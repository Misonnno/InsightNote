from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
import base64

app = FastAPI()

# å…è®¸è·¨åŸŸ (è®©å‰ç«¯èƒ½è¿ä¸Š)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Question(BaseModel):
    text: str

# ================= ğŸ”‘ å¯†é’¥é…ç½®åŒº (å¡«è¿™é‡Œï¼) =================

# 1. DeepSeek å®˜æ–¹é…ç½® (ä½ èŠ±äº†10å—é’±é‚£ä¸ª)
# ç”¨æ¥å¤„ç†çº¯æ–‡å­—å¯¹è¯
DEEPSEEK_API_KEY = "sk-f3d7c2773ef345b0a59694320058542c" 
DEEPSEEK_BASE_URL = "https://api.deepseek.com"

# 2. ç¡…åŸºæµåŠ¨é…ç½® (ç”¨æ¥è°ƒç”¨ Qwen çœ‹å›¾)
# å» https://cloud.siliconflow.cn/account/ak è·å–
SILICON_API_KEY = "sk-vxxgqmofwqfrpgbqccuapwxbbqxhtldsgjrrbuotaozsndjj" 
SILICON_BASE_URL = "https://api.siliconflow.cn/v1"

# è¿™é‡Œçš„æ¨¡å‹åå­—æˆ‘æ˜¯æ ¹æ®ä½ æˆªå›¾é‡Œæœ€å¼ºçš„é‚£ä¸ªå†™çš„
SILICON_VISION_MODEL = "Qwen/Qwen2.5-VL-72B-Instruct"

# ==========================================================

@app.post("/ask_ai")
def ask_ai(question: Question):
    """çº¯æ–‡å­—æ¨¡å¼ï¼šè°ƒç”¨ DeepSeek V3"""
    try:
        client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶å·¥ç¨‹å¯¼å¸ˆï¼Œå–„äºåˆ†æé”™é¢˜å’Œä»£ç ã€‚"},
                {"role": "user", "content": question.text}
            ],
            stream=False
        )
        return {"answer": response.choices[0].message.content}
    except Exception as e:
        print(f"DeepSeek æŠ¥é”™: {e}")
        return {"error": f"æ–‡å­—åˆ†æå¤±è´¥: {str(e)}"}

@app.post("/analyze_image")
async def analyze_image(text: str = Form(...), image: UploadFile = File(...)):
    """å›¾ç‰‡æ¨¡å¼ï¼šè°ƒç”¨ Qwen 2.5-VL (é€šè¿‡ç¡…åŸºæµåŠ¨)"""
    try:
        # 1. æŠŠä¸Šä¼ çš„å›¾ç‰‡è½¬æˆ Base64 æ ¼å¼
        image_content = await image.read()
        base64_image = base64.b64encode(image_content).decode('utf-8')
        
        # 2. è¿æ¥ç¡…åŸºæµåŠ¨
        client = OpenAI(api_key=SILICON_API_KEY, base_url=SILICON_BASE_URL)

        # 3. å‘é€è¯·æ±‚ (Qwen 2.5 VL)
        response = client.chat.completions.create(
            model=SILICON_VISION_MODEL, 
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": text}, # ç”¨æˆ·çš„é—®é¢˜
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}" # å›¾ç‰‡æ•°æ®
                            },
                        },
                    ],
                }
            ],
            stream=False
        )
        return {"answer": response.choices[0].message.content}

    except Exception as e:
        print(f"Qwen æŠ¥é”™: {e}")
        return {"error": f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}"}