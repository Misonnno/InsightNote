import os
import json
import re
import base64
from dotenv import load_dotenv
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = FastAPI()

# 2. å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- æ¨¡å‹å®šä¹‰ ---
class Question(BaseModel):
    text: str

# --- é…ç½®å¯†é’¥ ---
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")

SILICON_API_KEY = os.getenv("SILICON_API_KEY")
SILICON_BASE_URL = os.getenv("SILICON_BASE_URL", "https://api.siliconflow.cn/v1")
SILICON_VISION_MODEL = os.getenv("SILICON_VISION_MODEL", "Qwen/Qwen2.5-VL-72B-Instruct") 

# --- å·¥å…·å‡½æ•°ï¼šJSON æ¸…æ´— ---
def clean_json_response(content: str):
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        pass
    try:
        match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        json_str = match.group(1) if match else content
        # ä¿®å¤ LaTeX åæ–œæ 
        json_str = json_str.replace('\\', '\\\\').replace('\\\\\\\\', '\\\\') 
        start = json_str.find('{')
        end = json_str.rfind('}')
        if start != -1 and end != -1:
            return json.loads(json_str[start:end+1])
    except Exception as e:
        print(f"JSON Repair Failed: {e}")

    return {
        "title": "è§£æç»“æœ (è‡ªåŠ¨ä¿®å¤)",
        "conclusion": "è¯·æŸ¥çœ‹ä¸‹æ–¹è¯¦ç»†è§£æ",
        "analysis": content,
        "tags": ["AIè§£æ"]
    }

# ===========================
# ğŸš€ AI æ™ºèƒ½è§£ææ¥å£
# ===========================

@app.post("/ask_ai")
def ask_ai(question: Question):
    try:
        client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)
        system_prompt = """
        ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦æœ¯æ•™æˆã€‚
        ã€è¦æ±‚ã€‘ï¼š
        1. å…ˆè¿›è¡Œæ·±åº¦è§£æ(analysis)ï¼Œå†å¾—å‡ºç»“è®º(conclusion)ã€‚
        2. JSONå­—ç¬¦ä¸²ä¸­ LaTeX åæ–œæ å¿…é¡»è½¬ä¹‰ (ä¾‹å¦‚ \\\\frac)ã€‚
        """
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question.text}
            ],
            stream=False,
            response_format={ "type": "json_object" } 
        )
        return clean_json_response(response.choices[0].message.content)
    except Exception as e:
        print(f"DeepSeek Error: {e}")
        return {"error": str(e)}

@app.post("/analyze_image")
async def analyze_image(text: str = Form(...), image: UploadFile = File(...)):
    try:
        image_content = await image.read()
        base64_image = base64.b64encode(image_content).decode('utf-8')

        # Step 1: Qwen (çœ¼)
        client_vision = OpenAI(api_key=SILICON_API_KEY, base_url=SILICON_BASE_URL)
        ocr_prompt = """
        ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–ä¸“å®¶ã€‚
        1. ã€æ–‡æœ¬æå–ã€‘ï¼šæå–æ‰€æœ‰é¢˜ç›®æ–‡å­—ã€‚
        2. ã€è¡¨æ ¼æå–ã€‘ï¼šâš ï¸ åŠ¡å¿…é€è¡Œè¯»å–è¡¨æ ¼æ•°æ®ï¼Œä¸è¦é—æ¼ã€‚
        3. ã€è§†è§‰æè¿°ã€‘ï¼šæè¿°å‡ ä½•æˆ–æ‹“æ‰‘ç»“æ„ã€‚
        """
        vision_response = client_vision.chat.completions.create(
            model=SILICON_VISION_MODEL, 
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": ocr_prompt}, 
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
                    ],
                }
            ],
            stream=False,
            temperature=0.01,
        )
        visual_context = vision_response.choices[0].message.content

        # Step 2: DeepSeek (è„‘)
        client_logic = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)
        final_system_prompt = """
        ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„æ•™æˆã€‚
        ã€JSON æ ¼å¼ (é¡ºåºé‡è¦)ã€‘ï¼š
        {
          "title": "OCRé¢˜ç›®æ–‡æœ¬",
          "analysis": "è¯¦ç»†è§£æï¼ˆå…ˆå†™è¿™é‡Œï¼Œæ”¯æŒLaTeXï¼‰",
          "conclusion": "æœ€ç»ˆç­”æ¡ˆï¼ˆæœ€åå†™è¿™é‡Œï¼‰",
          "tags": ["çŸ¥è¯†ç‚¹"]
        }
        âš ï¸ JSON ä¸­ LaTeX åæ–œæ å¿…é¡»åŒå†™ (\\\\times)ã€‚
        """
        full_query = f"ã€è§†è§‰ä¿¡æ¯ã€‘:\n{visual_context}\nã€ç”¨æˆ·æŒ‡ä»¤ã€‘:\n{text}"
        
        logic_response = client_logic.chat.completions.create(
            model="deepseek-chat", 
            messages=[
                {"role": "system", "content": final_system_prompt},
                {"role": "user", "content": full_query}
            ],
            stream=False,
            response_format={ "type": "json_object" }
        )
        return clean_json_response(logic_response.choices[0].message.content)

    except Exception as e:
        print(f"Error: {e}")
        return {"title": "Error", "conclusion": "ç³»ç»Ÿå¼‚å¸¸", "analysis": str(e), "tags": ["Error"]}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)